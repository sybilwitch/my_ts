{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = 'all' #默认为'last'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方文档：\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST('./MNISTdata2/',\n",
    "                                     transform=torchvision.transforms.ToTensor())\n",
    "                                     #download=True)\n",
    "data_loader = torch.utils.data.DataLoader(trainset,batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.train_data)\n",
    "trainset.train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(data_loader):\n",
    "    if i==1:\n",
    "        print(data[0])\n",
    "        print(data[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./pics/LSTM_formula.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./pics/LSTM_parameters.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./pics/LSTM_outputs.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3328,  0.3045,  0.4220,  0.1886, -0.4886,  0.2109, -0.0916,\n",
       "           0.3310,  0.0517,  0.0819, -0.7193, -0.0687,  0.7380, -0.0205,\n",
       "          -0.0478,  0.0347,  0.3046, -0.1890,  0.1206,  0.3730],\n",
       "         [-0.0605,  0.5441,  0.0014,  0.0230, -0.1283, -0.4568, -0.0102,\n",
       "          -0.0758,  0.1814, -0.2447, -0.1990, -0.1460,  0.2621,  0.2209,\n",
       "          -0.0501, -0.0856, -0.3456,  0.1105,  0.2900, -0.0493],\n",
       "         [ 0.1685, -0.0151,  0.0681,  0.2222, -0.1754,  0.2434,  0.4500,\n",
       "           0.3014, -0.0464, -0.0817,  0.0868, -0.0448,  0.3186,  0.0192,\n",
       "          -0.3235,  0.0871,  0.1068, -0.4864,  0.3547, -0.0885]],\n",
       "\n",
       "        [[ 0.2386,  0.1256,  0.1105,  0.1029, -0.3401,  0.2743, -0.0969,\n",
       "           0.2890,  0.0638,  0.0988, -0.3004,  0.0345,  0.3122,  0.0506,\n",
       "          -0.0316,  0.0844,  0.1638, -0.0668,  0.0454,  0.2300],\n",
       "         [-0.0182,  0.3704,  0.0250,  0.0215, -0.1145, -0.1665, -0.0885,\n",
       "          -0.0010,  0.1397, -0.0327, -0.0534, -0.0711,  0.3707,  0.1409,\n",
       "          -0.1060, -0.0585, -0.1580,  0.0934,  0.2158,  0.0345],\n",
       "         [ 0.1110,  0.0418,  0.0595,  0.2273, -0.1197,  0.1377,  0.1274,\n",
       "           0.1574, -0.0536,  0.0282,  0.1401,  0.0459,  0.2078,  0.0592,\n",
       "          -0.2593,  0.0723,  0.1271, -0.1973,  0.2134, -0.0469]],\n",
       "\n",
       "        [[ 0.1334,  0.1060, -0.0234,  0.0273, -0.2311,  0.2271, -0.0808,\n",
       "           0.1683,  0.0032,  0.0583, -0.0986,  0.0612,  0.2286,  0.0464,\n",
       "          -0.0315,  0.0690,  0.1166, -0.0044,  0.0142,  0.0985],\n",
       "         [ 0.0171,  0.2641,  0.0016, -0.0183, -0.1177, -0.0342, -0.1045,\n",
       "           0.0295,  0.0674,  0.0225,  0.0203, -0.0248,  0.2943,  0.1212,\n",
       "          -0.1282, -0.0112, -0.0234,  0.0976,  0.1256,  0.0790],\n",
       "         [ 0.0734,  0.1022,  0.0326,  0.1208, -0.1069,  0.0885,  0.0346,\n",
       "           0.1137, -0.0599,  0.0418,  0.1279,  0.0873,  0.1587,  0.0587,\n",
       "          -0.1818,  0.0517,  0.1491, -0.0735,  0.1433, -0.0037]],\n",
       "\n",
       "        [[ 0.0784,  0.1057, -0.0551,  0.0405, -0.1448,  0.2153, -0.0756,\n",
       "           0.0812, -0.0472,  0.0383,  0.0382,  0.0580,  0.1359,  0.0694,\n",
       "          -0.0227,  0.0454,  0.1030,  0.0011,  0.0147,  0.0773],\n",
       "         [ 0.0400,  0.1663, -0.0361, -0.0248, -0.1046,  0.0422, -0.1104,\n",
       "           0.0282,  0.0234,  0.0424,  0.0559,  0.0016,  0.2306,  0.0917,\n",
       "          -0.1145,  0.0200,  0.0321,  0.0740,  0.0590,  0.0817],\n",
       "         [ 0.0523,  0.1258,  0.0160,  0.1060, -0.0713,  0.1090, -0.0305,\n",
       "           0.0604, -0.0659,  0.0501,  0.1307,  0.1087,  0.0954,  0.0641,\n",
       "          -0.1213,  0.0489,  0.1055, -0.0368,  0.1282,  0.0421]],\n",
       "\n",
       "        [[ 0.0593,  0.0923, -0.0660,  0.0243, -0.1147,  0.1888, -0.0767,\n",
       "           0.0303, -0.0789,  0.0323,  0.0909,  0.0414,  0.1067,  0.0550,\n",
       "          -0.0094,  0.0460,  0.1106,  0.0119,  0.0217,  0.0759],\n",
       "         [ 0.0415,  0.1149, -0.0541,  0.0010, -0.0913,  0.1001, -0.1011,\n",
       "           0.0279, -0.0147,  0.0386,  0.1085,  0.0105,  0.1630,  0.0850,\n",
       "          -0.0848,  0.0247,  0.0509,  0.0411,  0.0354,  0.0924],\n",
       "         [ 0.0486,  0.1233, -0.0151,  0.0825, -0.0577,  0.1227, -0.0574,\n",
       "           0.0422, -0.0705,  0.0594,  0.1279,  0.0733,  0.0736,  0.0602,\n",
       "          -0.0859,  0.0401,  0.0868, -0.0117,  0.0862,  0.0623]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#官方文档中的例子：\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2)  #input_size：10，hidden_size：20，两层LSTM；\n",
    "input = torch.randn(5, 3, 10)  #seq_len：5，batch：3，input_size：10\n",
    "h0 = torch.randn(2, 3, 20)  #layer_num：2，batch：3，hidden_size：20\n",
    "c0 = torch.randn(2, 3, 20)  \n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output\n",
    "output.size()\n",
    "#output：(seq_len,batch,hidden_size)，（5，3，20）\n",
    "#注意这里输出没有再进行线性变换，所以输出的维数与隐藏状态的维数是一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM\n",
    "#注意参数，LSTM的参数包括两个矩阵，两个偏置向量，\n",
    "#维数分别为：input_size * (4*hidden_size), hidden_size * (4*hidden_size)\n",
    "#4*hidden_size,4*hidden_size\n",
    "#另外两个是额外的（RNN初始化函数最后一行）的输出线性层的4*2矩阵和一个二维偏置向量。\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=3, #28,\n",
    "                          hidden_size=4, #64,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.out = nn.Linear(4,2)#(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        r_out,(h_n, h_c) = self.rnn(x)\n",
    "        out = self.out(r_out[:,-1,:])  #这里跟官方文档不一致，官方文档第二维是batch_size\n",
    "        #out = self.out(r_out)\n",
    "        return out\n",
    "    \n",
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rnn.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方文档中，LSTM类的参数为：\n",
    "\n",
    "* input_size：输入x中包含多少个特征；\n",
    "\n",
    "* hidden_size：隐藏状态h中包含多少个特征；\n",
    "\n",
    "* num_layders：recurrent层的数量。例如，如果设置为2，那么表示两个LSTM堆叠在一起，形成一个stacked LSTM，默认为1；\n",
    "\n",
    "* bias：如果设为false，那么层不应用bias权重b_ih和b_hh。默认为True。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0398, -0.3878],\n",
       "        [-0.0384, -0.3705],\n",
       "        [-0.0194, -0.3579],\n",
       "        [-0.0261, -0.3714],\n",
       "        [ 0.0292, -0.3386],\n",
       "        [-0.0493, -0.4011],\n",
       "        [ 0.0189, -0.3583],\n",
       "        [-0.0335, -0.4006],\n",
       "        [-0.0736, -0.4474],\n",
       "        [-0.1571, -0.4904]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#官方文档中，要求输入的\n",
    "#根据这个实验，输出是（10，2），\n",
    "#判断输入的第一维是batch_size；第二维是seq_len，第三维是input_size；\n",
    "\n",
    "testinput = torch.randn(10,4,3)\n",
    "out = rnn(testinput)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6642,  1.8331,  2.1584,  0.3587,  1.2044],\n",
       "         [ 1.3660,  1.3139, -1.3892, -0.6083, -1.6212],\n",
       "         [ 0.6929, -0.5200,  1.7226, -1.0205,  2.7657],\n",
       "         [-0.7322,  0.3355,  0.3247,  0.6266, -1.4932]],\n",
       "\n",
       "        [[ 1.0223, -0.8878, -0.4717,  1.9733, -0.8626],\n",
       "         [ 0.4447,  0.0779,  0.7690,  0.1739, -1.4704],\n",
       "         [-0.5244, -0.1656, -0.6172,  0.4475,  0.2278],\n",
       "         [ 2.0990, -1.3353, -0.0277,  1.5316, -1.1284]],\n",
       "\n",
       "        [[ 0.4707,  2.0543,  0.7990,  1.0356,  0.1714],\n",
       "         [-0.8572, -1.4685, -0.3881, -0.8228,  0.8629],\n",
       "         [ 0.6605,  1.6384,  0.8303,  0.2998,  0.4465],\n",
       "         [-0.6487,  0.0146, -0.4917, -1.1392,  0.4077]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6642,  1.8331,  2.1584,  0.3587,  1.2044],\n",
       "        [ 1.0223, -0.8878, -0.4717,  1.9733, -0.8626],\n",
       "        [ 0.4707,  2.0543,  0.7990,  1.0356,  0.1714]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4,5)\n",
    "a.size()\n",
    "a\n",
    "b = a[:,0,:]\n",
    "b.size()\n",
    "b\n",
    "a.size()[0]\n",
    "c = a.view(6,-1)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 0.7073,  1.4311, -0.1145]),\n",
       "indices=tensor([1, 2, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(b,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 16\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate\n",
    "DOWNLOAD_MNIST = False   # set to True if haven't download the data\n",
    "\n",
    "\n",
    "# Mnist digital dataset\n",
    "train_data = dsets.MNIST(\n",
    "    root='./MNIST_data',\n",
    "    train=True,                         # this is training data\n",
    "    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,            # download it if you don't have it\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())     # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()\n",
    "\n",
    "# Data Loader for easy mini-batch return in training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "test_data = dsets.MNIST(root='./MNIST_data', train=False, transform=transforms.ToTensor())\n",
    "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)\n",
    "test_y = test_data.test_labels.numpy()[:2000]    # covert to numpy array\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,         # rnn hidden unit\n",
    "            num_layers=1,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data\n",
    "        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)                   # (samples, time_step, input_size)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
